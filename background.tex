
\section{Background Information}
Extreme value theory (EVT) seeks to model and assess probability of observing
  extreme events.  Such a topic is applicable generally, but it finds
  particularly strong use among such fields as finance, climatology, and insurance.
  \findcite  In these fields, extreme events may represent significant loss to
  the body commissioning the study.  For instance, an insurance company might
  commission a study on extreme weather events, as a localized extreme event
  could cause a spike in claims from that region.

\subsection{Univariate EVT - Maxima}
Extreme value theory describes the asymptotic behavior of extreme events.  For a
  sample ${\bf x}$ where ${\bf x} = (x_1,\ldots,x_n)$ represents a sequence of
  independent random variables from a distribution function $F$, the
  distribution of the maximum $M_n$ of this sequence can be derived as:
\begin{equation*}
\begin{aligned}
\text{Pr}(M_n\leq z) &= \text{Pr}(X_1 \leq z, \ldots, X_n \leq z)\\
&= \text{Pr}(X_1\leq z)\times\ldots\times\text{Pr}(X_n\leq z)\\
&= F(z)^n
\end{aligned}
\end{equation*}
Where $F$ is unknown, we seek to approximate the behavior of $F^n$ as
  $n\rightarrow\infty$.  To ensure this doesn't degenerate to a point mass, we
  select a sequence of constants $a_n > 0$, $b_n$ and define $M_n^{\prime}$ as
  $M_n^{\prime} = (M_n - b_n)/a_n$, where $b_n$ represents the location, and
  $a_n$ the scale.  These sequences stabilize as $n$ increases, which creates a
  limiting distribution for $M_n^{\prime}$. To summarize, if there exists some
  sequence of constants $a_n > 0$, $b_n$ such that:
\begin{equation*}
\text{Pr}\left[\frac{M_n - b_n}{a_n} \leq z\right] \stackrel{d}{\rightarrow} G(z)
\end{equation*}
as $n\rightarrow\infty$, then $G$ is a max-stable distribution, and $F$ is in
  the domain of attraction of that max stable distribution.  The literature
  identifies 3 known max-stable distributions (Frechet, Weibull, and Gumbel)
  corresponding to different domains of attraction, and identifies them all as
  special cases of the \emph{Generalized Extreme Value} Distribution (GEV).
\begin{equation*}
  \label{eqn:gev}
  F(m \mid \mu, \sigma, \xi) = \exp\left\lbrace-\left[1 + \xi\left(\frac{x - \mu}{\sigma}\right)\right]^{-1/{\xi}}\right\rbrace
\end{equation*}
Thus, if $F$ is in the domain of attraction of any EVD, it will be in the domain
  of attraction of the GEV.  Max-stable distributions feature the homogeneity
  property:
\begin{equation*}
G^n(a_nz + b_n) = G(z)
\end{equation*}

For estimation, generally it will occur that we identify some natural block for
  the data.  For example, for temperature data taken hourly, we might identify a
  day (24 hours) as a block.  There's an implicit violation of the assumption of
  independence within a block, but that violation is generally ignored.  In data
  without a natural block, we are forced to specify a block size.  This has the \
  effect of reducing our sample size by a factor of $1/\text{block size}$.  In
  data with a natural block, this might be appropriate, but without a natural
  block this is extremely wasteful of data.

\subsection{Univariate EVT - Thresholding}
If $F$ is in the domain of attraction of an EVD, then for a random variable $X$
  that follows $F$, exceedances over a large threshold $u$ can be said to follow
  a Pareto distribution.  Again, let $X$ follow some distribution function $F$.
  Then let us regard observed values that exceed some threshold $u$ as extreme.
  It follows that:
\begin{equation*}
\text{Pr}\left[X > u + y\right] = \frac{1 - F(u + y)}{1 - F(u)}
\end{equation*}
for $y > 0$.  Let $X_1,\ldots,X_n$ be a sequence of random variables with the
  distribution function $F$.  Let $M_n = \max[x_1,\ldots,x_n]$.  Suppose that
  $F$ is in the domain of attraction of the GEV, such that for large $n$,
  $\text{Pr}[M_n \leq z]\approx G(z)$.  Then, for large enough $u$,
  $\text{Pr}[X > u+y\mid x > u]$ approximates to
\begin{equation*}
  \label{eqn:gp}
H(y) = 1 - \left(1 + \frac{\xi y}{\sigma}\right)^{-\frac{1}{\xi}}.
\end{equation*}
This defines the generalized Pareto family of distributions.  Thus, if block
  maxima have a limiting distribution $G$ within the EVD family, then threshold
  exceedances for a sufficiently high threshold have a limiting distribution $H$
  within the Generalized Pareto (GP) family.  Furthermore, the extremal index $\chi$
  will be the same for these two limiting distributions.

\subsection{Multivariate EVT}
Within multivariate EVT, we observe the joint behavior between extreme events.
  It is useful, at this juncture, to to standardize each variable $X_i$
  according to its marginal distribution.  Note, as has been stated, that
  threshold exceedances for a high threshold have a limiting distribution in the
  GP family.  Therefore, we estimate parameters for those marginal distributions
  considering only those observations that exceed the threshold.
  Standardization occurs as:
\begin{equation}
    z_j = \left(1 + \xi\frac{x_j - b_{t,j}}{a_{t,j}}\right)_{+}^{1/\xi}
\end{equation}
Note that $Z_j > 1$ implies that $x_j > b_{t,j}$, meaning that the observation
  $x$ is extreme in the $j$'th dimension.  Note also that $\sup_j Z_j$ follows a
  simple Pareto distribution.

\subsubsection{Limit Measures}
We assume the existence of a probability measure $\mu$ on ${\bf Z}$ such that
\begin{equation}
\lim_{n\rightarrow\infty}n\text{Pr}\left[\frac{1}{n}{\bf Z} \geq {\bf z}\right] = \mu\left([{\bf 0}, {\bf z}]^c\right)
\end{equation}
$\mu$ is thus the asymptotic distribution of ${\bf Z}$ in extreme regions.  It
  exhibits the homogeneity property, such that for any region A,
  $\mu(rA) = r^{-1}\mu(A)$.  By this property we can thus factorize ${\bf Z}$
  into two components:
\begin{equation}
  \begin{aligned}
    R &= \inorm{{\bf Z}} \in [1, \infty),\\
    {\bf V} &= \frac{{\bf Z}}{R} \in S_{\infty}^{d-1}.
  \end{aligned}
\end{equation}
That is, to say, we factorize ${\bf Z}$ into a radial component $R$, and an
  angular component, ${\bf V}$, which is the projection of ${\bf Z}$ onto the
  positive orthant of the $d$-dimensional unit hypersphere defined by the
  infinity norm, $S_{\infty}^{d-1}$. The radial component $R$, as we have
  stated, follows a simple pareto distribution, and by homogeneity property, is
  independent of the angular component ${\bf V}$.

As the angular component is now independent of the radial component, we can
  establish a distribution on the angular component.  For
  $B\subset S_{\infty}^{d-1}$, We define the spectral (or angular) measure,
  $\Omega(B)$, as
\begin{equation}
  \Omega(B) = \mu[{\bf z}: R({\bf z}) > 1, {\bf V} \in B].
\end{equation}
Then we can think of the spectral measure in terms of the limit measure $\mu$,
  and:
\begin{equation}
  \mu[{\bf z}:R(z)>t, {\bf V}\in B] = t^{-1}\Omega(B).
\end{equation}
Thus we see a one-to-one correspondance between the limit measure $\mu$ and the
  spectral measure $\phi$, and by factoring out the Pareto distributed radial
  component, we can establish a distribution on the angular component
\begin{equation}
  \text{Pr}\left({\bf V} \in B \mid r > 1\right) = \frac{\Omega(B)}{\Omega(S_{\infty}^{d-1})},
\end{equation}
\makenote{Paraphrasing from Goix et. al., figure if/how to cite}
conditioned on at least one of the components being extreme in the marginal
  sense.  It is using this property that we will establish our method.

For each $\nu\subset\lbrace{1,\ldots,d}, \nu \neq \emptyset$, we define the
  \emph{truncated cone} $\mathcal{C}_{\nu}$, where
\begin{equation}
    \mathcal{C}_{\nu} = \left\lbrace {\bf z} \geq 0 : \lVert z\rVert_{\infty}\geq 1, z_j \geq 0 \forall j \in \nu, z_j = 0 \forall j \not\in \nu\right\rbrace.
\end{equation}
That is, $\nu$ identifies a set index specifying components of the standardized
  data for which the observation is greater than 0.  The observation is greater
  than 0 for columns within that index, and 0 outside that index.  By
  construction, we're also requiring that the observation is greater than 1 in
  at least one of those dimensions.  By this definition, we observe that each
  $\mathcal{C}_{\nu}$ is distinct and disjoint from any other
  $\mathcal{C}_{\nu}$.  Now, defining $\Omega_{\nu}$ as the projection of
  $C_{\nu}$ onto $S_{\infty}^{d-1}$,
\begin{equation}
    \Omega_{\nu} = \left\lbrace {\bf v} \in S_{\infty}^{d-1} : x_i > 0 \forall i \in \nu, x_i = 0 \forall i \not\in \nu\right\rbrace,
\end{equation}
we can clearly see $\mu(\mathcal{C}_\nu) = \Phi(\Omega_{\nu})$ for all
  $\alpha \subset\lbrace1,\ldots,d\rbrace$.  Where we call $\mu(\dot)$ the limit
  measure, we refer to $\Phi(\dot)$ as the \emph{spectral} or
  \emph{angular measure}.  Our goal is establishing statistical inference on this
  angular measure.

% EOF
