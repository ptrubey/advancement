\documentclass{article}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{bibtex}
\usepackage{hyperref}

\title{Anomaly Detection using Extreme Value Theory}
\author{Peter Trubey}
\date{}

\begin{document}

\section{Introduction}

\section{Review of Extreme Value Theory}

\subsection{Univariate EVT - Maxima}
Extreme value theory describes the asymptotic behavior of extremes.  For a sample $x$ where $x = (x_1,\ldots,x_n)$ represents a sequence of independent random variables from a distribution function $F$, the distribution of the maximum $M_n$ of this sequence can be derived as:
\begin{equation*}
\begin{aligned}
\text{Pr}(M_n\leq z) &= \text{Pr}(X_1 \leq z, \ldots, X_n \leq z)\\
&= \text{Pr}(X_1\leq z)\times\ldots\times\text{Pr}(X_n\leq z)\\
&= F(z)^n
\end{aligned}
\end{equation*}
When $F$ is unknown, we seek to approximate the behavior of $F^n$ as $n\rightarrow\infty$.  To ensure this doesn't degenerate to a point mass, we select a sequence of constants $a_n > 0$, $b_n$ such that:
\begin{equation*}
M_n^{*} = \frac{M_n - b_n}{a_n}
\end{equation*}
This sequence stabilizes in location and scale as $n$ increases, which creates the limiting distribution for $M_n^{*}$. To summarize, if there exists some sequence of constants $a_n > 0$, $b_n$ such that:
\begin{equation*}
\text{Pr}\left[\frac{M_n - b_n}{a_n} \leq z\right] \stackrel{d}{\rightarrow} G(z)
\end{equation*}
as $n\rightarrow\infty$, then $G$ is a max-stable distribution, and $F$ is in the domain of attraction of that max stable distribution.  The literature identifies 3 known max-stable distributions (Frechet, Gumbel, ...) corresponding to different domains of attraction, and reformulates them in to one \emph{Generalized Extreme Value Distribution}.
\begin{equation*}
\text{Insert GEV equation here}
\end{equation*}
Thus, if $F$ is in the domain of attraction of any EVD, it will be in the domain of attraction of the GEV.  Max-stable distributions feature the homogeneity property:
\begin{equation*}
G^n(a_nz + b_n) = G(z)
\end{equation*}

For estimation, generally it will occur that we identify some natural block for the data.  For example, for temperature data taken hourly, we might identify a day (24 hours) as a block.  In data without a natural block, we are forced to specify a block size.  This has the effect of reducing our sample size.  In data with a natural block, this might be appropriate, but without a natural block this is extremely wasteful of data.

\subsection{Univariate EVT - Thresholds}
If $F$ is in the domain of attraction of an EVD, then for a random variable $X$ that follows $F$, exceedences over a threshold $u$ can be said to follow a Pareto distribution.  Again, let $x = (x_1,\ldots,x_n)$ independentally follow some distribution function $F$.  Then let us regard those observations that exceed some threshold $u$ as extreme.  It follows that:
\begin{equation*}
\text{Pr}\left[X_i > u + y\right] = \frac{1 - F(u + y)}{1 - F(u)}
\end{equation*}
for $y > 0$.

Let $X_1,\ldots,X_n$ be a sequence of random variables with the distribution function $F$.  Let $M_n = \max[x_1,\ldots,x_n]$.  Suppose that $F$ is in the domain of attraction of the GEV, such that for large $n$, $\text{Pr}[M_n \leq z]\approx G(z)$.  Then, for large enough $u$, $\text{Pr}[Y = x - u\mid x > u]$ is given as:
\begin{equation*}
H(y) = 1 - \left(1 + \frac{\xi y}{\sigma}\right)^{-\frac{1}{\xi}}
\end{equation*}
This defines the generalized pareto family of distributions.  Thus, if block maxima have a limiting distribution $G$ within the EVD family, then threshold exceedances for a high threshold have a limiting distribution $H$ in the Generalized Pareto (GP) family.

\subsection{Multivariate EVT}
Within multivariate EVT, we observe the joint behavior between extreme events.  Within our framework, we are specifically looking at exceedences over a threshold.  Again, let $X_j$ follow some distribution in the domain of attraction of $F_j$.  Then given   

\begin{equation}
C_{\alpha} = \lbrace V \geq 0 : \lVert V \rVert_{\infty}\rbrace
\end{equation}






\section{Review of Anomaly Detection}

\section{Methodology}
We examine th

Assuming that $X_j$ is in the domain of a max stable distribution for each $j$, then the univariate standardization of $X_{i}$ to GPD process occurs as follows:
\begin{equation}
Z_{ij]} = \left(1 + \gamma_j\frac{X_{ij} - b_{tj}}{a_{tj}}\right)_{+}^{1/\gamma_j}
\end{equation}
Where $b_{tj} = F^{-1}(1-1/t)$, and $a_{tj}$ and $\gamma_{j}$ are evaluated via maximum likelihood (need to fix).  This transformation is bounded at 0, so negative values after standardization are set to 0.  A standardized value greater than 1 indicates that the observation was extreme in that dimension.  Recognize that the observation $Z_i$ exists on the positive orthant in Euclidean space.  Additionally, we can transform $X \rightarrow (R,\theta)$, where:

\begin{equation}
  \begin{aligned}
    R &= \lVert Z \rVert_{\infty} = \max_{j \in (1,\ldots,d)} Z_i\\
    \omega &= \left(\frac{z_1}{R},\ldots,\frac{z_d}{R}\right) \in S_{\infty}^{d-1}\\
  \end{aligned}
\end{equation}

Now we are interested in the angular distribution of $\omega$, the projection of the observations onto the unit hypersphere. In order to parameterize that angular distribution, we employ the projected gamma distribution.

\subsection{Projected Gamma}
The projected gamma distribution is the product of $d$ independent gamma distributions.  That is, $y = (y_1,\ldots,y_d)$, and $y_i\sim\text{Ga}(\alpha_i,\beta_i)$.  From that, we employ a transformation to $d$-dimensional spherical coordinates $Y \rightarrow (r,\theta)$ as 
\begin{equation}
  \begin{aligned}
    y_1     &= r\cos\theta_1,\\
    y_2     &= r\sin\theta_1\cos\theta_2\\
            &\vdots\\
    y_{d-1} &= r\sin\theta_1\ldots\sin\theta_{d-2}\\
    y_{d}   &= r\sin\theta_1\ldots\sin\theta_{d-1}
  \end{aligned}
\end{equation}
where $r = \lVert Y\rVert_{2}$, the euclidean norm of $Y$.  The inverse of this transformation is:
\begin{equation}
  \begin{aligned}
    \theta_1     &= \cos^{-1}\left[\frac{y_1}{\lVert y_{1:d}\rVert}\right]\\
    \theta_2     &= \cos^{-1}\left[\frac{y_2}{\lVert y_{2:d}\rVert}\right]\\
                 &\vdots\\
    \theta_{d-1} &= \cos^{-1}\left[\frac{y_{d-1}}{\lVert y_{(d-1):d}\rVert}\right]
  \end{aligned}
\end{equation}



\subsection{Zero-Inflated Projected Gamma Model}


\subsection{Zero-Inflated Projected Gamma Mixture Model}



\section{Analysis}


\section{Results}


\section{Conclusion}





\end{document}