\documentclass[aspectratio=169]{beamer}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{soul}
\usepackage{algorithm2e}

\newcommand{\bruno}[1]{\textcolor{blue}{#1}} % Bruno Sanso edits- blue
\newcommand{\findcite}{{\color{red} [Find Citation]}}
\newcommand{\needcite}{\findcite}
\newcommand{\makenote}[1]{{\color{red} #1}}
\newcommand{\Chi}{\mbox{\Large$\chi$}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\inorm}[1]{\norm{#1}_{\infty}}
\newcommand{\pnorm}[2]{\norm{#1}_{#2}}

\newtheorem{prop}{Proposition}

\DeclareMathOperator{\tr}{Tr}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usetheme{Berlin}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{mini frames}{}
\setbeamertemplate{footline}{}
\renewcommand*{\slideentry}[6]{}

\makeatletter
\newlength{\frameheadheight}
\setlength{\frameheadheight}{2cm}
\newlength{\frametextheight}
\setlength{\frametextheight}{\paperheight}
\addtolength{\frametextheight}{-\footheight}
\addtolength{\frametextheight}{-\headheight}
\addtolength{\frametextheight}{-\frameheadheight}
\makeatother

\setcounter{tocdepth}{1}

\title{Multivariate Extreme Value Theory \\ and Applications to Anomaly Detection}
\author{Peter Trubey \\ Advisor: Bruno Sans{\'o}}
\institute{UCSC - Statistics Department}
\date[8/25/2021]{August 25, 2021}

\begin{document}

\begin{frame}[plain]
  \titlepage
\end{frame}

\begin{frame}[plain]
  \frametitle{Overview}
  \tableofcontents
\end{frame}

\section{Introduction}

\subsection{Integrated Vapor Transport}
\begin{frame}
  \frametitle{Integrated Vapor Transport}
  \begin{itemize}
      \item Slide in progress
      \item suffice to say: marginals of IVT are lognormal, in Gumbel D.o.A.
      \item 2 datasets; 8 and 47 cells
  \end{itemize}
\end{frame}

\subsection{Extreme Value Theory}

\begin{frame}
  \frametitle{EVT - A Brief Background}
  \begin{itemize}
    \item Why EVT?
        \begin{itemize}
            \item Inference on the tails of the distribution
            \item Inference beyond observed sample
        \end{itemize}
    \item Block Maxima - GEV
    \item Thresholding - GP
  \end{itemize}
\end{frame} % EVT Background
\begin{frame}
    \frametitle{Notation}
    \begin{itemize}
      \item Wedge Operators
        \begin{equation*}
            a \vee b = \max(a,b) \hspace{1cm} a\wedge b = \min(a,b)
        \end{equation*} 
      \item Positive orthant of unit $d$-sphere under $\mathcal{L}_{\infty}$ norm
        \begin{equation*}
          \mathcal{S}_{\infty}^{d-1} = \left\lbrace \bm{s} : \bm{s} \in [0,1]^d,\hspace{0.2cm}
                            \vee_{l=1}^d s_l = 1\right\rbrace
        \end{equation*}
    \end{itemize}
    
\end{frame} % Notation

\subsection{EVT - Block Maxima}

\begin{frame}
  \frametitle{Block Maxima}
  For $x_i \stackrel{\text{iid}}{\sim} F$, Let $M_n = \vee_{i=1}^n x_i$.
  \begin{equation*}
    \begin{aligned}
      \text{Pr}\left[M_n\leq z\right] &= \text{Pr}\left[X_1 \leq z, \ldots, X_n \leq z\right]\\
        &= \text{Pr}\left[X_1\leq z\right]\times\ldots\times\text{Pr}\left[X_n\leq z\right]\\
        &= F(z)^n.
    \end{aligned}
  \end{equation*}
  But if $F$ is unknown?

  How to keep from degenerating to a point mass?
\end{frame} % Block Maxima
\begin{frame}
  \frametitle{Block Maxima - Fisher-Tippett-Gnedenko Theorem}
  If there exists a sequence of constants $a_n > 0$, $b_n$ such that:
  \begin{equation*}
    \text{Pr}\left[\frac{M_n - b_n}{a_n} \leq z\right] \xrightarrow[\enskip n\to\infty\enskip]{} G(z)
  \end{equation*}

  Then $G$ is a \emph{max-stable distribution}, and $F$ is in its \emph{domain of attraction}.
\end{frame} % Fisher-Tippett Theorem 
\begin{frame}
  \frametitle{Block Maxima - GEV}
  \begin{itemize}
    \item 3 possible forms for these max stable distributions\\
      \hspace{1cm}Fr{\'e}chet, Gumbel, and Weibull
    \pause
    \item One unifying form
      \begin{equation*}
        F(m \mid \mu, \sigma, \xi) = \exp\left\lbrace-\left[1 +
              \xi\left(\frac{x - \mu}{\sigma}\right)\right]_{}^{-1/{\xi}}\right\rbrace.
      \end{equation*}
      the \emph{generalized extreme value distribution}
  \end{itemize}
\end{frame} % Block Maxima - GEV
\begin{frame}
  \frametitle{Block Maxima - Inference}
  \begin{itemize}
    \item Inference requires blocking data and taking maximum within a block
    \item Reduces data for inference to $1 / \text{block size}$.
    \item Enter - Thresholding
  \end{itemize}
\end{frame} % Block Maxima - Inference

\subsection{EVT - Thresholding}

\begin{frame}
  \frametitle{Thresholding - Pickands-Balkema-de Haan Theorem}
  \begin{itemize}
    \item For $X \sim F$:
      \begin{equation*}
        \text{Pr}\left[X > u + y\mid X > u\right] = \frac{1 - F(u + y)}{1 - F(u)}.
      \end{equation*}
    \pause
    \item If $F$ is in the domain of the GEV:
      \begin{equation*}
        \lim\limits_{u\to u^{\prime}}\text{Pr}\left[X > u + y\mid X > u\right] = H(y)
      \end{equation*}
    \pause
    \item Where $H$ has the form
      \begin{equation*}
        H(y) = 1 - \left(1 + \xi\frac{y}{\sigma}\right)^{-\frac{1}{\xi}}
      \end{equation*}
  \end{itemize}
\end{frame} % Thresholding - Pickands Balkema

\subsection{EVT - Multivariate Thresholding}

\begin{frame}
  \frametitle{Multivariate EVT}
  \begin{itemize}
    \item Standardize each $X_i$ according to its marginal distribution
        \begin{equation*}
          z_l = \left(1 + \xi_l\frac{x_l - b_{t,l}}{a_{t,l}}\right)_{+}^{1/\xi_l}
        \end{equation*}
		where $b_{t,l} = \hat{F}^{-1}(1 - 1/t)$.
    \item Note that $Z_l > 1\implies X_l > b_{t,l}$
    \item $\vee_l Z_l \sim \text{Pareto}$
	\item $\bm{a}$, $\bm{\xi}$ are found by MLE.
  \end{itemize}
\end{frame} % Multivariate EVT

\begin{frame}
  \frametitle{Multivariate EVT}
  \begin{itemize}
    \item Assume the existence of a limit measure $\mu$ on ${\bf Z}$ such that:
    \begin{equation*}
      n\text{Pr}\left(\frac{V_1}{n} \geq v_1 \text{ or }\ldots\text{ or }\frac{V_d}{n}\geq v_d\right)
      \rightarrow \mu\left([{\bf 0}, {\bf v}]^C\right)
    \end{equation*}
    \item $\mu$ is the asymptotic distribution of ${\bf Z}$ in extreme regions.
    \item $\mu$ features the homogeneity property, $\mu(t\cdot) = t^{-1}\mu(\cdot)$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Spectral Measure}
  For $B \subset S_{\infty}^{d-1}$, define the \emph{Spectral Measure}:
  \begin{equation*}
    \Omega(B) = \mu\left[{\bf z}: R({\bf z}) > 1, {\bf V} \in B\right].
  \end{equation*}
  Then,
  \begin{equation*}
    \mu\left[{\bf z}:R(z)>t, {\bf V}\in B\right] = t^{-1}\Omega(B).
  \end{equation*}
  Thus $t$ is independent of $\Omega$, the spectral measure.  This is completed as a
    probability measure as:
  \begin{equation*}
    \text{Pr}\left[{\bf V} \in B \mid r > 1\right] = \frac{\Omega(B)}{\Omega(S_{\infty}^{d-1})}
  \end{equation*}
  So conditional on at least one dimension exceeding its threshold, we can hold the
  angular measure independent of the magnitude.
\end{frame}

\section{Methodology}

\begin{frame}
  \frametitle{Casting \emph{Real} Data to $\mathcal{S}_{\infty}^{d-1}$}
  \begin{enumerate}
      \item Find $a_j, b_j, \xi_j$
      \item Standardize according to
        \begin{equation*}
         z_j = \left(1 + \xi\frac{x_j - b_{j}}{a_{j}}\right)_{+}^{1/\xi}
        \end{equation*}
      \item Calculate
        \begin{equation*}
            r_i = \vee_{l=1}^d z_{il},\hspace{1cm}\bm{v}_i = \frac{\bm{z}_i}{r_i}
        \end{equation*}
        
      \item $r_i\mid r_i \geq 1 \sim \text{Pareto}(1)$ $\rightarrow$ Keep where $r_i \geq 1$.
      \item Data is time series--decluster by keeping $\argmax_i r_i$ in series where $r_i > 1$
      \item $\bm{Z} \sim \text{MV Pareto}(1)$.  Dependence structure of $\bm{Z}$ expressed in $\bm{V}\in\mathcal{S}_{\infty}^{d-1}$.
  \end{enumerate}
\end{frame}

\subsection{Projection a Distribution to $\mathcal{S}_{\infty}^{d-1}$}

\begin{frame}
  \frametitle{The Unit $d$-Sphere in $\mathcal{L}_p$}
  \begin{columns}
    \begin{column}{.38\textwidth}
      \begin{itemize}
        \item $\mathcal{L}_p$ Norm:
          \begin{equation*}
            \lVert \bm{s}\rVert_p = \left[\sum_{l = 1}^ds_l^p\right]^{\frac{1}{p}}
          \end{equation*}
        \pause
        \item Unit Sphere on $\mathcal{L}_p$ Norm
          \begin{equation*}
            \mathcal{S}_{p}^{d-1} = \left\lbrace \bm{s} : 
                \bm{s}\in\mathcal{R}_+^d,\hspace{.2cm} \lVert\bm{s}\rVert_p = 1 \right\rbrace
          \end{equation*}
      \end{itemize}%
      \vfill
      ~
    \end{column}%
    \hfill%
    \begin{column}{.58\textwidth}
      \begin{center}
        \includegraphics[width = .8\linewidth, height = .8\linewidth]{./images/p_sphere}
      \end{center}
    \end{column}%
  \end{columns}%
\end{frame} % Unit Sphere - Description
\begin{frame}
  \frametitle{Projection onto the Unit Sphere}
  \begin{itemize}
    \item Take a distribution from $\mathcal{R}_+^{d}$ to $\mathcal{S}_{p}^{d-1}$
    \pause
    \item For finite $p$
      \begin{equation*}
        y_d = \left(1 - {\textstyle\sum}_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}
      \end{equation*}
    \pause
    \item Transformation to Radial, Angular
    \begin{equation*}
      T(x_1,\ldots,x_d) = \left(\pnorm{\bm{x}}{p}, \frac{x_1}{\pnorm{\bm{x}}{p}},
                    \ldots , \frac{x_{d-1}}{\pnorm{\bm{x}}{p}}\right) = (r,y_1,\ldots,y_{d-1})
    \end{equation*}
    \pause
    \begin{equation*}
    T^{-1}\left(r,y_1,\ldots,y_{d-1}\right) =
      \left(ry_1,\ldots,ry_{d-1}, r\left(1 - {\textstyle\sum}_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}\right)
    \end{equation*}
  \end{itemize}
\end{frame} % Unit Sphere - Projection
\begin{frame}
  \frametitle{Projection - Jacobian}
  \begin{equation*}
    \begin{bmatrix}
      y_1 & r & 0 & \ldots & 0\\
      y_2 & 0 & r & \ldots & 0\\
      \vdots & \vdots & \vdots & \ddots & \vdots\\
      y_{d-1} & 0 & \ldots & 0 & r \\
      \left(1 - {\scriptsize\sum_{l=1}^{d-1}}y_l^p\right)^{1/p} &
        - ry_1^{p-1}\phi & -ry_2^{p-1}\phi & \cdots & -ry_{d-1}\phi
    \end{bmatrix}
  \end{equation*}
  where $\phi = \left(1 - {\scriptsize\sum_{l=1}^{d-1}}y_l^p\right)^{1/p - 1}$
  \pause
  \begin{equation*}
  \lvert J \rvert = r^{d-1}\left[\left(1 - {\textstyle\sum}_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}} +
      {\textstyle\sum}_{l = 1}^{d-1}y_l^p\left(1 - {\textstyle\sum}_{l=1}^{d-1}
          y_l^p\right)^{\frac{1}{p} - 1}\right]
  \end{equation*}
\end{frame} % Unit Sphere - Jacobian

\subsection{Projected Gamma Family}
\begin{frame}
  \frametitle{Projected Gamma Distribution}
  \begin{itemize}
    \item Assume a product of independent Gammas
      \begin{equation*}
        f(r,\bm{y}) = \prod_{l = 1}^d \text{Ga}\left(ry_l\mid\alpha_l,\beta_l\right)
        \lvert J \rvert I_{\bm{y} \in \mathcal{S}_{p}^{d-1}}
      \end{equation*}
    \pause
    \item Expanded Form
      \begin{equation*}
        f(r,\bm{ y}) = \prod_{l = 1}^{d}
        \left[\frac{\beta_l^{\alpha_l}}{\Gamma(\alpha_l)}(ry_l)^{\alpha_l - 1}
                    \exp\lbrace-\beta_lry_l\rbrace\right]
        \times r^{d-1}\left[y_d - {\textstyle \sum}_{l = 1}^{d-1}y_l^p
                  \left(y_d^p\right)^{\frac{1}{p} - 1}\right]
      \end{equation*}
    \pause
    \item Integrate out radial component; left with distribution on angular
      \begin{equation*}
        \text{PG}(\bm{ y}\mid\bm{ \alpha},\bm{ \beta}) = \prod_{l = 1}^d\left[\frac{\beta_l^{\alpha_l}}{\Gamma(\alpha_l)}y_l^{\alpha_l - 1}\right]
          \times \left[y_d - {\textstyle \sum}_{l = 1}^{d-1}y_l^p\left(y_d^p\right)^{\frac{1}{p} - 1}\right]
          \times \frac{\Gamma({\textstyle\sum}_{l = 1}^d\alpha_l)}{\left({\textstyle\sum}_{l = 1}^d \beta_ly_l\right)^{{\scriptstyle\sum_{l = 1}^d \alpha_l}}}
      \end{equation*}
  \end{itemize}
\end{frame} % Projected Gamma Distribution
\begin{frame}
  \frametitle{Data augmentation}
  \begin{itemize}
    \item Sample from full conditional for $r$
      \begin{equation*}
        r\mid\bm{ \alpha},\bm{ \beta}, y \sim \text{Ga}\left(r\mid{\textstyle\sum}_{l = 1}^d \alpha_l,
              {\textstyle\sum}_{l = 1}^d \beta_ly_l\right).
      \end{equation*}
    \pause
    \item To recover independent Gammas interetation
      \begin{equation*}
        L(\bm{\alpha},\bm{\beta} \mid \bm{r},\bm{y}) \propto
            \prod_{i = 1}^n\prod_{l = 1}^{d}\text{Ga}\left(r_iy_{il}\mid\alpha_l,\beta_l\right)
      \end{equation*}
    \pause
    \item Enabling independent inference between columns
      \begin{equation*}
        L(\alpha_l,\beta_l) \propto \prod_{i = 1}^n
                  \text{Ga}\left(r_iy_{il}\mid\alpha_l,\beta_l\right)
      \end{equation*}
  \end{itemize}
\end{frame} % Data Augmentation
\begin{frame}
  \frametitle{Projected Gamma Model}
  \begin{equation*}
    \begin{aligned}
      \bm{ y}\mid\bm{\alpha},\bm{\beta} &\sim \text{PG}(\bm{ y}\mid\bm{\alpha},\bm{\beta})\\
      \bm{ \alpha},\bm{\beta} &\sim {\textstyle \prod}_{l = 1}^d \text{Ga}(\alpha_l \mid \xi_l,\tau_l)
              \times {\textstyle \prod}_{l = 2}^d \text{Ga}(\beta_l\mid \zeta_l,\sigma_l).
    \end{aligned}
  \end{equation*}
\end{frame} % Vanilla Model
\begin{frame}
  \frametitle{Projected Gamma Model - Inference}
  \begin{itemize}
    \item Full conditional for $\beta_l$
      \begin{equation*}
        \beta_l\mid \bm{ y}, r, \alpha_l \sim \text{Ga}\left(n + \alpha_l + \zeta_l,
                {\textstyle \sum}_{i = 1}^nr_iy_{il} + \sigma_l\right)
      \end{equation*}
    \pause
    \item Log-posterior for $\alpha_l$
      \begin{equation*}
        f(\alpha_l \mid \bm{ y}, r) \propto
          \frac{\left({\textstyle \prod}_{i = 1}^nr_iy_{il}\right)^{\alpha_l - 1}}{
            \Gamma^n(\alpha_l)} \times \alpha_l^{\xi_l - 1}\exp\{-\tau_l\alpha_l\} \times
            \frac{\Gamma(n\alpha_l + \zeta_l)}{
            \left({\textstyle\sum}_{i = 1}^n r_iy_{il} + \sigma_l
                  \right)^{(n * \alpha_l + \zeta_l)}}
      \end{equation*}
    \pause
    \item If $\beta_l = 1$, then
    \begin{equation*}
      f(\alpha_1 \mid \bm{ y}, r) \propto
        \frac{{\textstyle\prod}_{i = 1}^n ry_{i1}^{\alpha_1 - 1}}{\Gamma^n(\alpha_1)} \times
        \alpha_1^{\xi_1 - 1}\exp\{-\tau_1\alpha_1\}
    \end{equation*}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Dirichlet Process Mixture Model}
  \begin{equation*}
    \begin{aligned}
      \bm{ y}_i &\sim \text{PG}\left(\bm{ y}\mid \bm{ \alpha}_i, \bm{ \beta}_i\right)\\
      (\alpha_i,\beta_i) &\sim \text{DP}\left(\eta, G_0\right)\\
      &~\hspace{-2cm}G_0 = {\textstyle\prod}_{l = 1}^d\text{Ga}\left(\alpha_{jl}\mid\xi_{l},\tau_{l}\right)
                    \times{\textstyle\prod}_{l=2}^d\text{Ga}\left(\beta_{jl}\mid\zeta_{l}\tau_{l}\right)
    \end{aligned}
    \hspace{1cm}
    \begin{aligned}
      \bm{ \xi},\bm{ \tau} &\sim {\textstyle \prod}_{l = 1}^d \text{Ga}(\xi_l\mid a,b)
              \times \text{Ga}(\tau_l\mid c,d)\\
      \bm{ \zeta},\bm{\sigma} &\sim {\textstyle\prod}_{l = 2}^d\text{Ga}(\zeta_l \mid a,b)
              \times \text{Ga}(\sigma_l\mid c,d)\\
      \bm{ \eta} &\sim \text{Ga}(\eta \mid 2, 0.1).
    \end{aligned}
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Log-normal Prior for Shape Parameters}
  \begin{equation*}
    \begin{aligned}
      \bm{ y}_i &\sim \text{PG}\left(\bm{ y}\mid \bm{ \alpha}_i, \bm{\beta}_i\right)\\
      (\bm{\alpha}_i, \bm{\beta}_i) &\sim \text{DP}\left(\eta, G_0\right)\\
        &~\hspace{-1cm}G_0 = \mathcal{N}\left(\log\bm{ \alpha}_{j}\mid\mu,\Sigma\right)\times
            {\textstyle\prod}_{l = 2}^d\text{Ga}\left(\beta_{jl}\mid\zeta_l,\sigma_l\right)
    \end{aligned}
    \hspace{1cm}
    \begin{aligned}
      \mu,\Sigma &\sim \mathcal{N}\left(\mu\mid\mu_0,\Sigma_0\right)
                                  \times \text{IG}\left(\nu,\Psi\right)\\
      \bm{ \zeta},\bm{\sigma} &\sim {\textstyle\prod}_{l = 2}^d\text{Ga}(\zeta_l \mid a,b)
                                \times \text{Ga}(\sigma_l \mid c,d) \\
      \bm{ \eta} &\sim \text{Ga}(\eta \mid 2, 0.1).
    \end{aligned}
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Choice of Norm}
  \begin{itemize}
    \item $\bm{V} \in \mathcal{S}_{\infty}^{d-1}$
    \pause
    \item Easy to project distribution in $\mathcal{R}_+^{d}$ to $\mathcal{S}_{p}^{d-1}$ for any finite $p$
    \pause
    \item Difficult to project distribution in $\mathcal{R}_+^{d}$ to $\mathcal{S}_{\infty}^{d-1}$
    \pause
    \item Project to $\mathcal{S}_{p}^{d-1}$ for large $p$, then project posterior predictive samples
  \end{itemize}
\end{frame}

\subsection{Alternative Geometries}

\begin{frame}
  \frametitle{Alternative Geometries}
  \begin{itemize}
    \item Coordinate system to describe $\mathcal{S}_p^{d-1}$ in $\omega^{d-1}$
    \item $\mathcal{L}_1$: Log-ratios:  $\mathcal{S}_1^{d-1} \rightarrow (-\infty,\infty)^{d-1}$
    \item $\mathcal{L}_2$: Spherical Coordinates: $\mathcal{S}_2^{d-1} \rightarrow [0,\pi/2]^{d-1}$
    
      \begin{equation*}
        \begin{aligned}
        \theta_l &= \cos^{-1}\left(\frac{y_l}{\lVert \bm{y}_{l:d}\rVert_2}\right)\\
        &\hspace{1cm}\text{for }l = 1,\ldots,d-1
        \end{aligned}
        \hspace{1cm}
        \begin{aligned}
          y_1 &= \cos\theta_1\\
          y_l &= \left[{\textstyle\prod}_{k = 1}^{l-1}\sin\theta_k\right]\cos\theta_l\\
          &\hspace{1cm}\text{for }l = 2,\ldots,d-1\\
          y_d &= {\textstyle\prod}_{k = 1}^{d-1}\sin\theta_k
        \end{aligned}
      \end{equation*}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Probit-Normal}
  Let $Q_i = \text{Probit}(2\theta_i / \pi)$, for $i = 1,\ldots,d-1$
  \begin{equation*}
    \begin{aligned}
                Q_i &\sim \mathcal{N}_{d-1}\left(\mu_i, \Sigma_i\right)\\
    \mu_i, \sigma_i &\sim \text{DP}(\eta, G_0)\\
                    &\hspace{-1cm}G_0 =
                      \mathcal{N}_{d-1}(\mu_i\mid\mu_0,\Sigma_0)\times \text{IW}(\Sigma_i\mid\nu,\Psi)
    \end{aligned}
    \hspace{1cm}
    \begin{aligned}
              \mu_0 &\sim \mathcal{N}_{d-1}\left({\bf u},{\bf S}\right)\\
           \Sigma_0 &\sim \text{IW}(\nu_0,\Psi_0)\\
               \eta &\sim \text{Ga}(\alpha, \beta)
    \end{aligned}
  \end{equation*}
\end{frame}

\section[Model Comparison]{Model Comparison on $\mathcal{S}_{\infty}^{d-1}$}

\begin{frame}
  \frametitle{Model Comparison on $\mathcal{S}_{\infty}^{d-1}$}
  \begin{itemize}
      \item Density is \emph{difficult}
      \item Multivariate distribution
      \item Have samples from posterior predictive
      \begin{itemize}
          \item Energy Score
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Energy Score}
  \begin{itemize}
    \item Generalization of CRPS to multiple dimensions
    \begin{equation*}
      \label{eq:es}
      \text{ES}\left(P,x_i\right) =  \text{E}_p g\left(\bm{X}_i, \bm{x}_i\right)
                - \frac{1}{2}\text{E}_p g\left(\bm{X}_i,\bm{X}_i^{\prime}\right)
    \end{equation*}
    \pause
    \item Where $g$ is a negative definite kernel\\
      Euclidean distance is most common
    \pause
    \item What is most appropriate on the hypercube?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Positive Orthant of $\mathcal{S}_{\infty}^{d-1}$}
  \begin{center}
    \includegraphics[width=0.8\linewidth]{./images/rotation}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Distance on $\mathcal{S}_{\infty}^{d-1}$}
  \begin{itemize}
    \item Length of the shortest path between two points
    \pause
    \item A distance:
      \begin{itemize}
        \item is symmetric
        \item is positive
        \item respects triangle inequality
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Rotation - 1d and 2d}
    \begin{center}
        \includegraphics[height = \frametextheight]{./images/rot_3d_2d}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Rotation - 3d}
    \begin{center}
        \includegraphics[height=\frametextheight]{./images/rot_4d_3d}
    \end{center}
\end{frame}

\begin{frame}
  \frametitle{A Valid Negative Definite Kernel}
  \begin{prop}
    For points $a,b \in \mathcal{S}_{\infty}^{d-1}$ a valid negative definite kernel can be formed as
    \begin{equation*}
      g(\bm{a},\bm{b}) = \begin{cases}
        \pnorm{\bm{b}-\bm{a}}{2} &\text{ if }\argmax_l\bm{a} = \argmax_l\bm{b}\\
        \pnorm{\bm{c}-\bm{a}}{2} + \pnorm{\bm{b}-\bm{c}}{2} &\text{ otherwise}
      \end{cases}
    \end{equation*}
    where $\bm{c}$ resides on the intersection between the faces of $\bm{a}$ and $\bm{b}$, and
                minimizes $g(\bm{a},\bm{b})$.
  \end{prop}
\end{frame}


\section{Results}

\subsection{Simulation}

\begin{frame}
  \frametitle{Simulation Study}
  \begin{itemize}
    \item Finite mixture of Gammas
    \item For each Number of Mixture Components (3,6,9,12):
      \begin{itemize}
        \item Generate a data-set of 20 columns
        \item output subsets of c = 3,6,12,20 columns projected onto $\mathcal{S}_{\infty}^{c-1}$.
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Simulation - Energy Score}
  \begin{center}
    \includegraphics[height=\frametextheight]{./images/simulation_es}
  \end{center}
\end{frame}


\subsection{Integrated Vapor Transport}

\begin{frame}
  \frametitle{IVT - Energy Score}
  \begin{center}
    \include{table_dev}
  \end{center}
\end{frame}

\section[EVT Applications]{Applications of EVT Analysis}

\begin{frame}
  \frametitle{Applications of EVT Analysis}
  \begin{itemize}
    \item Pairwise Extremal Dependence Coefficients
    \item Conditional Survival Functions
      \begin{itemize}
        \item Reciprocal of Conditional Return Levels
      \end{itemize}
  \end{itemize}
\end{frame}

\subsection{Pairwise Extremal Dependence Coefficients}

\begin{frame}
  \frametitle{Pairwise Extremal Dependence Coefficients}
    \begin{itemize}
      \item A summary measure of extremal dependence
      \begin{equation*}
        \chi_{kl} = \lim\limits_{u\to\infty}\text{P}\left(Z_k > u\mid Z_l > u\right).
      \end{equation*}
      \pause
      \item Bounded to $[0,1]$
        \begin{itemize}
          \item $0$ represents asymptotic independence
          \item A Pareto model can not represent asymptotic independence
        \end{itemize}
      \pause
      \item Reformulated to unit hypercube
        \begin{equation*}
          \chi_{kl} = \text{E}\left[\frac{V_k}{\text{E}(V_k)}{\bigwedge}\frac{V_l}{\text{E}(V_l)}\right]
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{IVT - Extremal Dependence}
  \begin{minipage}{.49\textwidth}
    \centering
    \includegraphics[width=0.99\linewidth]{./images/chi_ij_8}
  \end{minipage}
  \begin{minipage}{.49\textwidth}
    \centering
    \includegraphics[width=0.99\linewidth]{./images/chi_ij_46}
  \end{minipage}
\end{frame}

\subsection{Conditional survival functions}

\begin{frame}
  \frametitle{Conditional Survival Function}
  \begin{prop}
      In one dimension, the conditional survival function can be calculated as
   \begin{equation*}
      \label{eqn:condsurv1df}
      \text{P}\left[Z_l > z_l\mid {\bf Z}_{\neg(l)} > {\bf z}_{\neg(l)}\right] =
        \frac{\text{E}\left[\bigwedge_{k = 1}^d \frac{V_k}{z_k}\right]}{
                      \text{E}\left[\bigwedge_{k \neq l}\frac{V_k}{z_k}\right]}
    \end{equation*}
      where $\bm{V} = \bm{Z} / \pnorm{\bm{Z}}{\infty}$.
  \end{prop}
\end{frame}

\begin{frame}
  \frametitle{Conditional Survival Function - Cont.}
  \begin{footnotesize}
  \begin{equation*}
    \label{eqn:condsurv1d}
    \text{P}\left[Z_l > z_l\mid {\bf Z}_{-(l)} > {\bf z}_{-(l)}\right] =
      \frac{\text{P}\left[\cap_{k = 1}^d Z_k > z_k\right]}{\text{P}\left[\cap_{k \neq l} Z_k > z_k\right]}.
  \end{equation*}
  \pause
  $R = \pnorm{{\bf Z}}{\infty}$, ${\bf V} = \frac{{\bf Z}}{R}$, such that
    ${\bf V}\in \mathcal{S}_{\infty}^{d-1}$.  Then ${\bf Z} = R{\bf V}$.
  \begin{equation*}
    \text{P}\left(\cap_{k = 1}^d Z_k > z_k\right) = \text{P}\left(\cap_{k = 1}^d RV_k > z_k\right)
  \end{equation*}
  \pause
  Recall, for standard Pareto, $\text{P}(R > r) = 1\wedge\frac{1}{r}$.
  \begin{equation*}
    \text{P}\left[\bigcap_{k = 1}^d R > \frac{z_k}{v_k}\right] =
      \text{P}\left[R  > \bigvee_{k=1}^d\frac{z_k}{V_k}\right] =
      \text{E}\left[1 \bigwedge \left(\bigvee_{k = 1}^d\frac{z_k}{V_k}\right)^{-1}\right]
  \end{equation*}
  $V_k \in [0,1]$; $z_k > 1$ (for the region of interest) $\implies$ $\frac{z_k}{V_k} > 1$
  \pause
  \begin{equation*}
    \text{P}\left[\cap_{k = 1}^d Z_k > z_k\right] = \text{E}\left[\wedge_{k = 1}^d\frac{V_i}{z_i}\right].
  \end{equation*}
  \pause
  And similar for the denominator
  \begin{equation*}
    \text{P}\left[Z_l > z_l\mid {\bf Z}_{\neg(l)} > {\bf z}_{\neg(l)}\right] =
      \frac{\text{E}\left[\wedge_{k = 1}^d \frac{V_k}{z_k}\right]}{\text{E}\left[
                \bigwedge_{k \neq l}\frac{V_k}{z_k}\right]}
  \end{equation*}
  \end{footnotesize}
\end{frame}

\begin{frame}
  \frametitle{IVT - Conditional Survival 1d}
  \begin{center}
    \includegraphics[height=\frametextheight,width=\textwidth]{./images/condsurv_1d}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{IVT - Conditional Survival 2d (selected)}
  \begin{center}
    \includegraphics[height=\frametextheight,width=\frametextheight]{./images/condsurv_2d}
  \end{center}
\end{frame}

\section[Anomaly]{Applications to anomaly detection}

\begin{frame}
  \frametitle{What is an anomaly?}
  \begin{itemize}
    \item Anomalies are:
      \begin{itemize}
        \item Observations with large outliers?
        \item Observations with outsized effects?
        \item Data that is \emph{different}.
        \item Data from regions of data sparsity
      \end{itemize}
    \item Desire anomaly \emph{scores}--larger$\rightarrow$more anomalous
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Classical Anomaly Detection Methods}
  \begin{itemize}
    \item Clustering methods
      \begin{itemize}
        \item Linkage-based (single, \dots, complete)
        \item Centroid-based ($k$-Means)
        \item Density-based (DBSCAN)
      \end{itemize}
    \item Non-statistical Models
      \begin{itemize}
        \item Isolation Forest
        \item One-class SVM
        \item Local Outlier Factor
      \end{itemize}
    \item Statistical Models
      \begin{itemize}
        \item Gaussian mixture models
        \item If you can generate a density directly\dots
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Proposed Anomaly Scoring Methods}
  \begin{itemize}
    \item Density Estimation on the hypersphere
    \item Contribution to Posterior Predictive Loss
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Density Estimation on the Hypersphere}
  \begin{itemize}
    \item Sample from posterior predictive distribution
    \item Density based on \emph{distance} to $k$th nearest neighbor
    \begin{equation*}
        S_{i,(k)}^{-1} =
          \frac{k}{N}\frac{\Gamma\left(\frac{d-1}{2} - 1\right)}{\pi^{\frac{d-1}{2}}D_{k}^{d-1}(V_i)}
    \end{equation*}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Anomaly Detection Results (Simulated Data)}
  \begin{center}
    \include{table_ad_sim_results}
  \end{center}
\end{frame}

\section[Scaling]{Scaling to higher dimensions}

\begin{frame}
  \frametitle{Scaling to Higher Dimensions}
  \begin{itemize}
    \item Compuitational advances in modelling
      \begin{itemize}
        \item Variational Bayes
      \end{itemize}
    \item Maintaining Model Fidelity at Scale
      \begin{itemize}
        \item Gaussian Mixture on $\log\alpha$
        \item $\eta$-Cones
      \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Scale - Mixture of Gammas Prior}
  \begin{itemize}
    \item $\eta \subset \lbrace 1,\ldots,d\rbrace$.  Define the $\eta$-Cone:
      \begin{equation*}
        \mathcal{C}_{\eta} = \left\lbrace \bm{z} : z_l > 0 \text{ for }l\in\eta;
                              \hspace{0.2cm} z_l = 0 \text{ for }l\not\in\eta\right\rbrace
      \end{equation*}
    \pause
    \item Gamma models do not have support at 0--$\epsilon$-thickened cones
      \begin{equation*}
        \mathcal{C}_{\eta}^{(\epsilon)} = \left\lbrace \bm{z} : z_l \geq \epsilon
          \text{ for }l\in\eta; \hspace{0.2cm} z_l = 0 \text{ for }l\not\in\eta\right\rbrace
      \end{equation*}
    \pause
    \item How does this help us?
      \begin{itemize}
        \item For Gamma models, $\alpha < 1$ $\implies$ mass near 0
        \item A mixture of gammas for $\alpha_l$:
          \begin{equation*}
            \alpha_l \sim I_{l\in\eta}\text{Ga}(\alpha_l\mid a_1, 1)
                        + I_{l\not\in\eta}\text{Ga}(\alpha_l\mid a_0, 1)
          \end{equation*}
          with $\alpha_0 < 1$, $\alpha_1 > 1$
      \end{itemize}
  \end{itemize}
\end{frame}

\section{Conclusion}

\subsection{Summary}

\begin{frame}
  \frametitle{Conclusion}
  \begin{itemize}
    \item Developed a means of describing the dependence structure of the multivariate Pareto
    \item Demonstrated inherent difficulty in distribution on $\mathcal{S}_{\infty}^{d-1}$
      \begin{itemize}
        \item developed a means of model comparison on the space
      \end{itemize}
    \item Applied models to IVT data
      \begin{itemize}
        \item Pairwise Extremal Dependence Coefficients
        \item Conditional Survival Curves
      \end{itemize}
    \item Anomaly Detection (Preliminary)
    \item Modelling at Scale (on the horizon)
  \end{itemize}
\end{frame}

\subsection{Timeline}

\begin{frame}
    \frametitle{Timeline}
    \begin{center}
        \includegraphics[width=\textwidth]{./images/timeline}
    \end{center}
\end{frame}


\begin{frame}
    
\end{frame}


\appendix

\begin{frame}
  \frametitle{Kullbeck Liebler Divergence}
  \begin{itemize}
    \item KL Divergence
      \begin{equation*}
        D_{\text{KL}}(A,B) = \int_{x\in \Omega(A)}A(x)\log\left(\frac{A(x)}{B(x)}\right)\text{d}x
      \end{equation*}
      requires an estimate of density.
    \pause
    \item We have demonstrated the difficulty of establishing density.  Approximate
      \begin{equation*}
      D_{\text{KL}}^{(k)}(A,B) = \log\frac{n(B)}{n(A)} + c(A) \left[\rho_A^{(k)}(B)
                                                      - \rho_A^{(k)}(A)\right]
      \end{equation*}
  \end{itemize}
\end{frame} % KL Divergence (Introduction)
\begin{frame}
  \frametitle{Finite Mixture Model}
  \begin{equation*}
    \begin{aligned}
      \bm{ y}_i &\sim \sum_{j = 1}^J\pi_j\text{PG}\left(\bm{ y}\mid \bm{ \alpha}_j, \bm{ \beta}_j\right)\\
      \bm{ \alpha}_j &\sim {\textstyle \prod}_{l = 1}^d \text{Ga}\left(\alpha_l\mid\xi_l,\tau_l\right)\\
      \bm{ \beta}_j &\sim {\textstyle \prod}_{l = 2}^d \text{Ga}\left(\beta_l\mid\zeta_l,\sigma_l\right)
    \end{aligned}
    \hspace{2cm}
    \begin{aligned}
      \bm{ \xi},\bm{\tau} &\sim {\textstyle \prod}_{l = 1}^d \text{Ga}(\xi_l\mid a,b)
                \times \text{Ga}(\tau_l\mid c,d)\\
      \bm{ \zeta},\bm{\sigma} &\sim {\textstyle\prod}_{l = 2}^d\text{Ga}(\zeta_l \mid a,b)
              \times \text{Ga}(\sigma_l\mid c,d)\\
      \bm{ \pi} &\sim \text{Dir}(\pi_0)
    \end{aligned}
  \end{equation*}
\end{frame} % Projected Gamma - Finite Mixture Model

\begin{frame}
  \frametitle{Simulation - Posterior predictive loss}
  \begin{center}
    \includegraphics[height=\frametextheight]{./images/simulation_ppl}
  \end{center}
\end{frame}
\begin{frame}
  \frametitle{Simulation - KL Divergence}
  \begin{center}
    \includegraphics[height=\frametextheight]{./images/simulation_knn_kld}
  \end{center}
\end{frame}


\begin{frame}
  \frametitle{IVT - Posterior Predictive Loss}
  \begin{center}
    \includegraphics[height=\frametextheight]{./images/simulation_knn_kld}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{IVT - KL Divergence}
  \begin{center}
    \includegraphics[height=\frametextheight]{./images/knn_kld}
  \end{center}
\end{frame}


\end{document}
