\subsection{Projection onto an arbitrary unit hypersphere}
A hypersphere is a geometric object such that the distance from any point to the center takes a fixed,
  constant value.  The unit hypersphere is a hypersphere where that distance is 1. We can define the
  hypersphere under an arbitrary distance measurement, but let's take the $\mathcal{L}_p$ norm. Let
  the $\mathcal{L}_p$-norm be defined as
  \begin{equation*}
    \lVert \bm{s} \rVert_p = \left(\sum_{l = 1}^d \lvert s_l\rvert^p\right)^{\frac{1}{p}}.
  \end{equation*}
  From this, we establish the $\mathcal{L}_1$ norm as $p = 1$, or the absolute sum, the
  $\mathcal{L}_2$ norm, as $p = 2$, the Euclidean distance.  From this we also establish the
  $\mathcal{L}_{\infty}$ norm, as
  \begin{equation*}
    \lVert \bm{s} \rVert_{\infty}
      = \lim\limits_{p\to\infty} \lVert \bm{s} \rVert_p
      = \max_{l\in\lbrace1,\ldots,d\rbrace_l}s_l.
  \end{equation*}
  We are interested in the direction, or angular component, of vectors described in the positive
  orthant, $\mathcal{R}_{+}^d$.  One means of describing the direction of a vector in
  $\mathcal{R}_+^d$ is to project that vector onto $\mathcal{S}_{p}^{d-1}$, the positive orthant of
  the unit hypersphere defined on an $\mathcal{L}_p$-norm, denoted as $\mathcal{S}_{p}^{d-1}$.  That is,
  \begin{equation*}
    \mathcal{S}_{p}^{d-1} = \left\lbrace \bm{y} : \bm{y} \in \mathcal{R}_{+}^{d}, \lVert \bm{y}\rVert_{p} = 1\right\rbrace.
  \end{equation*}
  We project an observation onto this space by dividing said observation by its $p$-norm. Let
  $\bm{x}\in \mathcal{R}_{+}^{d}$, then $\bm{y} = \bm{x} / \lVert \bm{x}\rVert_p \in \mathcal{S}_{p}^{d-1}$.
  We denote the $d-1$ to indicate the loss of one degree of freedom relative to the original vector.
  Observations on one hypersphere can be projected without loss of information onto another by
  dividing by the target hypersphere's defining norm.

Assuming $\bm{y} \in \mathcal{S}_{p}^{d-1}$, then for finite $p$, $y_d$ can always be represented
  as a function of the other dimensions.  That is,
  \begin{equation*}
    y_d = \left(1 - \sum_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}.
  \end{equation*}
  So the transformation
  \begin{equation}
    \label{eqn:pnormt}
    T(x_1,\ldots,x_d) = \left(\pnorm{\bm{x}}{p}, \frac{x_1}{\pnorm{\bm{x}}{p}},
                          \ldots , \frac{x_{d-1}}{\pnorm{\bm{x}}{p}}\right) = (r,y_1,\ldots,y_{d-1})
  \end{equation}
  does not lose any information.  The reverse of this transformation,
  \begin{equation}
    \label{eqn:pnormtinv}
    T^{-1}\left(r,y_1,\ldots,y_{d-1}\right) =
      \left(ry_1,\ldots,ry_{d-1}, r\left(1 - {\scriptstyle\sum}_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}\right)
  \end{equation}
  equivalently recovers the original data.  Transforming random variables such that we want to recover
  the new density requires multiplying by the determinant of the Jacobian--the matrix of derivatives
  of the inverse transformation.  For this transformation, that value takes the form:
  \begin{equation}
    \label{eqn:pnormjac}
    r^{d-1}\left[\left(1 - \sum_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}} +
        \sum_{l = 1}^{d-1}y_l^p\left(1 - \sum_{l=1}^{d-1} y_l^p\right)^{\frac{1}{p} - 1}\right].
  \end{equation}
  Notice a factor of $r^{d-1}$ independent of $p$. We refer to $\bm{y}$ and $r$ as, respectively,
  the angular and radial components of $\bm{x}$.  If we assume a distribution for $\bm{x}$, then
  by transforming to $r, \bm{y}$ and integrating out $r$, we are left with a distribution on solely
  the angular component, or, equivalently, the projection of the vector $\bm{x}$ onto
  $\mathcal{S}_{p}^{d-1}$.
  \bruno{\bf The idea is there, but you need to make the explanation that starts at the beginning
  of the section and ends here much sharper. }

Many of the models we present here follow this form, where we, for reasons to be elaborated, assume
  a $d$-dimensional Gamma distribution on this hypothetical $\bm{x}$. For finite $p$, this has a
  direct benefit in that it is easy to integrate out $r$.  As we saw with the Jacobian computed
  earlier, no matter what $p$, the Jacobian always has a factor of $r^{d-1}$.  With the independent
  Gamma model, $r$ easily integrates out as a gamma distribution.  We can also perform data
  augmentation generating latent $r$'s, and recovering the ability to do independent inference on
  the parameters of those gamma distributions.  We investigated other unidimensional distributions
  with support on $\mathcal{R}_+$ in the hopes we could perform the same dimension reduction with a
  different parameterization, but none offered the flexibility of the Gamma while allowing $r$ to be
  integrated out in closed form.
  \bruno{\bf You can probably summarize this paragraph with two or three sentences saying that you
   use a product of independent gamma distributions on the components of $x_j$ for convenience and tractability.}

One might question why we don't use this method to construct a distribution directly on
  $\mathcal{S}_{\infty}^{d-1}$, the unit hypersphere under $\mathcal{L}_{\infty}$.  Put simply, we
  encounter a problem in the transformation.  If we examine the the determinant of the Jacobian
  under the $\mathcal{L}_{p}$ norm, we have a factor along the lines of
  \begin{equation*}
    \left(1 - \sum_{l = 1}^{d-1}y_i^p\right)^{\frac{1}{p} - 1}
  \end{equation*}
  which, if we take the limit as $p$ approaches infinity, if any other $y_l$ than $y_d$ is equal to
  1, then that value approaches $0^{-1}$--an impossibility.  Another way we can recognize the problem
  is directly in the transformation--$T^{-1}(r,y_1,\ldots,y_{d-1})$ will not recover $\bm{x}$ if
  any $y_l$ other than $y_d$ is 1, or equivalently $\max_l x_l\neq x_d$.  Thus, we see a clear
  breaking point between inference conducted on the finite $p$ hypersphere, $\mathcal{S}_{p}^{d-1}$,
  and the $\mathcal{L}_{\infty}$ hypersphere, $\mathcal{S}_{\infty}^{d-1}$.
  \bruno{\bf I am not sure I understand what you are trying to say in the paragraph.}

As an alternative to this projected distribution model, one method we might consider would be to map
  to an alternative geometry, where we can express those $d-1$ degrees of freedom in a $d-1$
  dimensional vector.  In such a space, we can assign whatever model seems appropriate without the
  degrees of freedom restriction necessary in the projected gamma model.  Choosing what $\mathcal{L}_p$
  norm hypersphere we start mapping from identifies what possible geometries we might use.  For instance,
  on the $\mathcal{L}_1$ norm, a possible geometry might be isometric or additive
  logratios~\citep{aitchison1982}.  On the $\mathcal{L}_2$ hypersphere, we consider spherical
  coordinate transformation. Let $\bm{y} \in \mathcal{S}_{2}^{d-1}$. Then, we transform $\bm{y}$
  to spherical coordinates as
  \begin{equation*}
    \theta_l = \arccos\frac{y_l}{\pnorm{\bm{y}_{l:d}}{2}},
  \end{equation*}
  for $l = 1,\ldots, d-1$. That is, the arccosine of the ratio of the mass of a given element,
  versus the \emph{combined} mass of that and subsequent elements.  If $x_l = 0$, and
  $\pnorm{\bm{x}_{l:d}}{2} > 0$, then $\theta_l = \frac{\pi}{2}$, indicating that all the mass was
  in later dimensions.  Alternatively, if $\theta_l = 0$, then that indicates all the mass was in
  the current element.  One can see here that ordering of the axes has a great effect on the
  resulting coordinates.  The inverse of this transformation takes the form:
  \begin{equation}
    \label{eqn:spherical}
    \begin{aligned}
      y_1 &= \cos\theta_1\\
      y_l &= \prod_{k = 1}^{l-1}\sin\theta_k\cos\theta_l \hspace{1cm}\text{for } l = 2,\ldots,d-1\\
      y_d &= \prod_{k = 1}^{d-1}\sin\theta_k
      % y_2 &= \sin\theta_1\cos\theta_2\\
      % &\hspace{0.2cm}\vdots\\
      % y_{d-1} &= \sin\theta_1\ldots\sin\theta_{d-2}\cos\theta_{d-1}\\
      % y_d &= \sin\theta_1\ldots\sin\theta_{d-1}
    \end{aligned}
  \end{equation}
  \cite{nunez2019} use this transformation to project a product of Gammas distribution in
  $\mathcal{R}^d$ onto $[0,2\pi]^{d-1}$ Alternatively, we then map these spherical coordiates via
  probit transformation to $(-\infty,\infty)$ to consider a multivariate normal distribution.

% EOF
