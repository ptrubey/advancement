\subsection{Projection onto an arbitrary unit hypersphere}
A hypersphere is a geometric object such that the distance from any point to the center takes a fixed,
  constant value.  The unit hypersphere is a hypersphere where that distance is 1. We can define the
  hypersphere under an arbitrary distance measurement, but let's take the $\mathcal{L}_p$ norm. Let
  the $\mathcal{L}_p$-norm be defined as
  \begin{equation*}
    \lVert \bm{s} \rVert_p = \left(\sum_{l = 1}^d \lvert s_l\rvert^p\right)^{\frac{1}{p}}.
  \end{equation*}
  From this, we establish the $\mathcal{L}_1$ norm as $p = 1$, or the absolute sum, the
  $\mathcal{L}_2$ norm, as $p = 2$, the Euclidean distance.  From this we also establish the
  $\mathcal{L}_{\infty}$ norm, as
  \begin{equation*}
    \lVert \bm{s} \rVert_{\infty}
      = \lim\limits_{p\to\infty} \lVert \bm{s} \rVert_p
      = \max_{l\in\lbrace1,\ldots,d\rbrace}s_l.
  \end{equation*}
  We are interested in the direction, or angular component, of vectors described in the positive
  orthant, $\mathcal{R}_{+}^d$.  One means of describing the direction of a vector in
  $\mathcal{R}_+^d$ is to project that vector onto $\mathcal{S}_{p}^{d-1}$, the positive orthant of
  the unit hypersphere defined on an $\mathcal{L}_p$-norm, denoted as $\mathcal{S}_{p}^{d-1}$.  That is,
  \begin{equation*}
    \mathcal{S}_{p}^{d-1} = \left\lbrace \bm{y} : \bm{y} \in \mathcal{R}_{+}^{d}, \lVert \bm{y}\rVert_{p} = 1\right\rbrace.
  \end{equation*}
  We project an observation onto this space by dividing said observation by its $p$-norm. Let
  $\bm{x}\in \mathcal{R}_{+}^{d}$, then $\bm{y} = \bm{x} / \lVert \bm{x}\rVert_p \in \mathcal{S}_{p}^{d-1}$.
  We denote the $d-1$ to indicate the loss of one degree of freedom relative to the original vector.
  Observations on one hypersphere can be projected without loss of information onto another by
  dividing by the target hypersphere's defining norm.

Assuming $\bm{y} \in \mathcal{S}_{p}^{d-1}$, then for finite $p$, $y_d$ can always be represented
  as a function of the other dimensions.  That is,
  \begin{equation*}
    y_d = \left(1 - \sum_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}.
  \end{equation*}
  So the transformation
  \begin{equation}
    \label{eqn:pnormt}
    T(x_1,\ldots,x_d) = \left(\pnorm{\bm{x}}{p}, \frac{x_1}{\pnorm{\bm{x}}{p}},
                          \ldots , \frac{x_{d-1}}{\pnorm{\bm{x}}{p}}\right) = (r,y_1,\ldots,y_{d-1})
  \end{equation}
  does not lose any information.  The reverse of this transformation,
  \begin{equation}
    \label{eqn:pnormtinv}
    T^{-1}\left(r,y_1,\ldots,y_{d-1}\right) =
      \left(ry_1,\ldots,ry_{d-1}, r\left(1 - {\scriptstyle\sum}_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}}\right)
  \end{equation}
  equivalently recovers the original data.  Transforming random variables such that we want to recover
  the new density requires multiplying by the determinant of the Jacobian--the matrix of derivatives
  of the inverse transformation.  For this transformation, that value takes the form:
  \begin{equation}
    \label{eqn:pnormjac}
    r^{d-1}\left[\left(1 - \sum_{l = 1}^{d-1}y_l^p\right)^{\frac{1}{p}} +
        \sum_{l = 1}^{d-1}y_l^p\left(1 - \sum_{l=1}^{d-1} y_l^p\right)^{\frac{1}{p} - 1}\right].
  \end{equation}
  Notice a factor of $r^{d-1}$ independent of $p$. We refer to $\bm{y}$ and $r$ as, respectively,
  the angular and radial components of $\bm{x}$.  If we assume a distribution for $\bm{x}$, then
  by transforming to $r, \bm{y}$ and integrating out $r$, we are left with a distribution on solely
  $\bm{y}$, the projection of $\bm{x}$ onto $\mathcal{S}_{p}^{d-1}$.
  \bruno{\bf The idea is there, but you need to make the explanation that starts at the beginning
  of the section and ends here much sharper. }

The models we present here follow this form, where we assume a $d$-dimensional Gamma distribution on
  this hypothetical $\bm{x}$. As we saw with the Jacobian computed earlier, no matter what $p$, the
  Jacobian always has a factor of $r^{d-1}$.  Starting from independent Gammas, $r$ easily integrates
  out as a gamma distribution.  During inference, we recover a fully conjugate Gibbs sampling method
  by performing data augmentation to recover the latent $\bm{R}$, and thus recovering the ability to
  do independent inference on the parameters of those gamma distributions.

% We encounter a problem in evaluating a density projected in this manner onto $\mathcal{S}_{\infty}^{d-1}$,
%   the unit hypersphere under $\mathcal{L}_{\infty}$.  In the determinant of the Jacobian of the
%   transformation onto the $\mathcal{L}_p$ norm, we observe a factor of
%   \begin{equation*}
%     \left(1 - \sum_{l = 1}^{d-1}y_i^p\right)^{\frac{1}{p} - 1}.
%   \end{equation*}
%   When we attempt to take the limit of this quantity as $p\to\infty$, if any $y_l$ other than $y_d$
%   equals to 1 (that is, if any column other than the last is max), then this factor approaches $0^{-1}$.
%   Thus, we can not evaluate a density for a distribution projected onto $\mathcal{S}_{\infty}^{d-1}$.

For an alternative to this projected distribution model, one method we might consider would be to map
  to an alternative geometry, where we can express those $d-1$ degrees of freedom in a $d-1$
  dimensional vector.  In such a space, we can assign whatever model seems appropriate without the
  degrees of freedom restriction necessary in the projected gamma model.  Choosing what $\mathcal{L}_p$
  norm hypersphere we start mapping from identifies what possible geometries we might use.  For instance,
  on the $\mathcal{L}_1$ norm, a possible geometry might be isometric or additive
  logratios~\citep{aitchison1982}.  On the $\mathcal{L}_2$ hypersphere, we consider spherical
  coordinate transformation. Let $\bm{y} \in \mathcal{S}_{2}^{d-1}$. Then, we transform $\bm{y}$
  to spherical coordinates as
  \begin{equation*}
    \theta_l = \arccos\frac{y_l}{\pnorm{\bm{y}_{l:d}}{2}},
  \end{equation*}
  for $l = 1,\ldots, d-1$. That is, the arccosine of the ratio of the mass of a given element,
  versus the \emph{combined} mass of that and subsequent elements.  If $x_l = 0$, and
  $\pnorm{\bm{x}_{l:d}}{2} > 0$, then $\theta_l = \frac{\pi}{2}$, indicating that all the mass was
  in later dimensions.  Alternatively, if $\theta_l = 0$, then that indicates all the mass was in
  the current element.  One can see here that ordering of the axes has a great effect on the
  resulting coordinates.  The inverse of this transformation takes the form:
  \begin{equation}
    \label{eqn:spherical}
    \begin{aligned}
      y_1 &= \cos\theta_1\\
      y_l &= \left[\prod_{k = 1}^{l-1}\sin\theta_k\right]\cos\theta_l \hspace{1cm}\text{for } l = 2,\ldots,d-1\\
      y_d &= \prod_{k = 1}^{d-1}\sin\theta_k
    \end{aligned}
  \end{equation}
  \cite{nunez2019} use this transformation to project a product of Gammas distribution in
  $\mathcal{R}^d$ onto $[0,2\pi]^{d-1}$ Alternatively, we then map these spherical coordiates via
  probit transformation to $(-\infty,\infty)$ to consider a multivariate normal distribution.

% EOF
